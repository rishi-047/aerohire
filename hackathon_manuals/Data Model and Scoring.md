# Data Model and Scoring

This guide explains the database schema and the scoring system.

## Core Tables

User
- Stored in `users`
- Fields: `id`, `email`, `hashed_password`, `full_name`, `role`

Candidate
- Stored in `candidates`
- Fields: `resume_parsed_data`, `resume_text_raw`, `technical_score`, `psychometric_score`, `ai_rationale`, `hiring_recommendation`, `confidence_score`, `status`

CodeSubmission
- Stored in `code_submissions`
- Fields include:
  - `submitted_code`
  - `tests_passed`, `tests_total`
  - `execution_time_ms`
  - `code_history`
  - `char_breakdown`
  - `chat_response`, `teamwork_score`

ProctoringLog
- Stored in `proctoring_logs`
- Fields: `event_type`, `severity`, `timestamp`

## Technical Score

Calculated in:
- `backend/app/api/v1/assessment.py`

Rules:
- Only expected coding question IDs are counted.
- Each question score is `tests_passed / tests_total`.
- The final score is the average over expected questions.
- Missing questions count as 0.

## Psychometric Score

Calculated in frontend:
- Q3 correct choice adds 50 points.
- Q4 text length over 50 adds 50 points.

Stored in:
- `candidate.psychometric_score`

## Integrity Score

Calculated from proctoring logs:
- LOW = -2
- MEDIUM = -5
- HIGH = -10
- Minimum 0

## Originality Ratio

Computed from `char_breakdown`:
- typed vs pasted character counts
- ratio = typed / (typed + pasted)

## Teamwork Score

Generated by:
- `analyze_chat_response()` in `glass_box.py`
- Uses Gemini or fallback heuristic

Stored in:
- `code_submissions.teamwork_score`

## Status Lifecycle

Common values:
- Registered
- Assessment Started
- Completed
- Under Review
- Interview Scheduled
- Hired
- Rejected
